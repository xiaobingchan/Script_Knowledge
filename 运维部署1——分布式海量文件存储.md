# https://www.cnblogs.com/kevingrace/p/9141432.html

yum install -y --downloadonly --downloaddir=/root/yum           ntp 
yum install -y --downloadonly --downloaddir=/root/ntpdate       ntpdate 
yum install -y --downloadonly --downloaddir=/root/ntp-doc       ntp-doc
yum install -y --downloadonly --downloaddir=/root/ceph          ceph
yum install -y --downloadonly --downloaddir=/root/ceph-deploy   ceph-deploy
yum install -y --downloadonly --downloaddir=/root/ceph-radosgw  ceph-radosgw
yum install -y --downloadonly --downloaddir=/root/ceph-fuse     ceph-fuse
yum install -y --downloadonly --downloaddir=/root/createrepo     createrepo

节点	    Hostname	IP地址	            属性
Deploy节点	ceph-manage	192.168.244.176 	ceph-deploy
OSD节点1	osd1	    192.168.244.177 	osd1
OSD节点2  	osd2	    192.168.244.178	    osd2

cat >> /etc/sysconfig/network-scripts/ifcfg-ens33 <<EOF
IPADDR="192.168.244.176"
NETMASK="255.255.255.0"
GATEWAY="192.168.244.0"
EOF
systemctl restart network

# 每个节点修改
hostnamectl set-hostname ceph-admin
hostnamectl set-hostname ceph-node1
hostnamectl set-hostname ceph-node2

# 所有节点
cat >> /etc/hosts << EOF
192.168.244.176    ceph-admin
192.168.244.177    ceph-node1 
192.168.244.178    ceph-node2
EOF
systemctl stop firewalld
systemctl disable firewalld
sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config
setenforce 0

yum -y install wget
yum clean all
rm -rf /etc/yum.repos.d/*.repo
wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo
sed -i '/aliyuncs/d' /etc/yum.repos.d/CentOS-Base.repo
sed -i '/aliyuncs/d' /etc/yum.repos.d/epel.repo
sed -i 's/$releasever/7.6.1810/g' /etc/yum.repos.d/CentOS-Base.repo
cat >> /etc/yum.repos.d/CentOS-Base.repo << EOF
[ceph]
name=ceph
baseurl=http://mirrors.aliyun.com/ceph/rpm-jewel/el7/x86_64/
gpgcheck=0
priority =1
[ceph-noarch]
name=cephnoarch
baseurl=http://mirrors.aliyun.com/ceph/rpm-jewel/el7/noarch/
gpgcheck=0
priority =1
[ceph-source]
name=Ceph source packages
baseurl=http://mirrors.aliyun.com/ceph/rpm-jewel/el7/SRPMS
gpgcheck=0
priority=1
EOF

cat > /etc/yum.repos.d/local.repo << EOF
[localsource]
name=\"CentOS7\"
baseurl=file://home/cephuser/yumresp
enabled=1
gpgcheck=0
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7
EOF

yum install -y ntp ntpdate ntp-doc
ntpdate 0.us.pool.ntp.org
hwclock --systohc
systemctl enable ntpd.service
systemctl start ntpd.service


password=123456
username=cephuser
adduser -d /home/${username} -m ${username}
echo "${password}" | passwd ${username} --stdin
echo "ceph ALL = (root) NOPASSWD:AL" | sudo tee /etc/sudoers.d/ceph
chmod 0440 /etc/sudoers.d/ceph
chmod -R 775 /home/cephuser
sed -i s'/Defaults requiretty/#Defaults requiretty'/g /etc/sudoers
vi /etc/sudoers
#################################
cephuser ALL=(ALL)      ALL
#################################

# admin节点
su - cephuser
ssh-keygen -t rsa
cp /home/cephuser/.ssh/id_rsa.pub /home/cephuser/.ssh/authorized_keys
scp -r /home/cephuser/.ssh ceph-node1:/home/cephuser/
scp -r /home/cephuser/.ssh ceph-node2:/home/cephuser/

# OSD节点
parted -s /dev/sdb mklabel gpt mkpart primary xfs 0% 100%
mkfs.xfs /dev/sdb -f
blkid -o value -s TYPE /dev/sdb

# 所有节点
su - cephuser
ssh -p22 cephuser@ceph-admin
ssh -p22 cephuser@ceph-node1
ssh -p22 cephuser@ceph-node2

# admin节点
sudo yum  -y install ceph-deploy--no-adjust-repos
su - cephuser
mkdir cluster
cd cluster/
su -
cd /home/cephuser/cluster/
ceph-deploy new ceph-admin
cat >> ceph.conf << EOF
public network = 192.168.244.0/24
osd pool default size = 2
EOF
ceph-deploy --overwrite-conf config push  ceph-node1 ceph-node2 
ceph-deploy install ceph-admin ceph-node1 ceph-node2 --no-adjust-repos
# 所有节点
chmod -R 777 /var/lib/ceph/mon
chmod -R 777 /var/run/ceph/
chown -R ceph:ceph /var/lib/ceph/mon
chown -R ceph:ceph /var/run/ceph/
# admin节点
ceph-deploy --overwrite-conf mon create-initial # 确保hostname正确
ceph-deploy gatherkeys ceph-admin
ceph-deploy disk list ceph-node1 ceph-node2
ceph-deploy disk zap ceph-node1:/dev/sdb ceph-node2:/dev/sdb
ceph-deploy osd prepare ceph-node1:/dev/sdb ceph-node2:/dev/sdb
ceph-deploy osd activate ceph-node1:/dev/sdb ceph-node2:/dev/sdb
ceph-deploy disk list ceph-node1 ceph-node2

chmod 644 /etc/ceph/ceph.client.admin.keyring
# admin节点
ceph health
ceph -s
osd stat
ceph osd stat
ceph osd tree
ceph mds stat
ceph-deploy mds create ceph-admin
ceph mds stat
ceph osd lspools
ceph osd pool create cephfs_data 10
ceph osd pool create cephfs_metadata 10 
ceph fs new myceph cephfs_metadata cephfs_data
ceph osd lspools
ceph mds stat
ceph -s